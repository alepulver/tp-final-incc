{
 "metadata": {
  "name": "Test classification methods with CV"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import book_classification as bc\n",
      "import shelve\n",
      "import pandas\n",
      "import numpy\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import svm, decomposition, cross_validation, pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3.3/importlib/_bootstrap.py:313: UserWarning: Module argparse was already imported from /usr/lib/python3.3/argparse.py, but /home/ale/Programs/my-python3-env/lib/python3.3/site-packages is being added to sys.path\n",
        "  return f(*args, **kwds)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myShelf = shelve.open(\"storage_new.db\")\n",
      "aBookCollection = myShelf['aBookCollection']\n",
      "print(len(aBookCollection))\n",
      "del myShelf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "597\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with bc.RandomContext(123):\n",
      "    anotherCollection = aBookCollection.selection().exclude_authors_below(7)\n",
      "    print(len(anotherCollection))\n",
      "    train_collection, test_collection = anotherCollection.selection().split_per_author_percentage(0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "508\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Try entropies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = bc.BasicTokenizer()\n",
      "grouper = bc.FixedGrouper(500)\n",
      "extractor = bc.EntropiesExtractor(tokenizer, grouper)\n",
      "matrix_extractor = bc.SklExtractor(extractor)\n",
      "predictor = pipeline.Pipeline([\n",
      "\t\t('extractor', matrix_extractor),\n",
      "\t\t('svd', decomposition.TruncatedSVD(50)),\n",
      "\t\t('svm', svm.SVC(class_weight='auto'))])\n",
      "books, authors = train_collection.as_arrays()\n",
      "scores = cross_validation.cross_val_score(predictor, books, authors,\n",
      "\tscoring='accuracy', cv=cross_validation.StratifiedKFold(authors, n_folds=4))\n",
      "    #scoring='accuracy', cv=cross_validation.ShuffleSplit(len(authors)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([ 0.74444444,  0.62921348,  0.73033708,  0.69662921])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Try frequencies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = bc.BasicTokenizer()\n",
      "grouper = bc.FixedGrouper(500)\n",
      "extractor = bc.FrequenciesExtractor(tokenizer)\n",
      "matrix_extractor = bc.SklExtractor(extractor)\n",
      "predictor = pipeline.Pipeline([\n",
      "\t\t('extractor', matrix_extractor),\n",
      "\t\t('svd', decomposition.TruncatedSVD(50)),\n",
      "\t\t('svm', svm.SVC(class_weight='auto'))])\n",
      "books, authors = train_collection.as_arrays()\n",
      "scores = cross_validation.cross_val_score(predictor, books, authors,\n",
      "\tscoring='accuracy', cv=cross_validation.StratifiedKFold(authors, n_folds=4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([ 0.11111111,  0.04494382,  0.13483146,  0.04494382])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Try TF-IDF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "predictor = pipeline.Pipeline([\n",
      "\t\t('extractor', TfidfVectorizer()),\n",
      "\t\t('svd', decomposition.TruncatedSVD(50)),\n",
      "\t\t('svm', svm.SVC(class_weight='auto'))])\n",
      "books, authors = train_collection.as_arrays()\n",
      "scores = cross_validation.cross_val_score(predictor, [b.contents() for b in books], authors,\n",
      "\tscoring='accuracy', cv=cross_validation.StratifiedKFold(authors, n_folds=4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([ 0.11111111,  0.04494382,  0.14606742,  0.04494382])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Try log(frequencies) and remove words with few/many occurrences, also "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "import numpy\n",
      "\n",
      "class Transformer:\n",
      "    def __init__(self, op):\n",
      "        self._op = op\n",
      "    def fit(self, a, b=None):\n",
      "        return self\n",
      "    def transform(self, matrix):\n",
      "        return self._op(matrix)\n",
      "\n",
      "extractor = bc.FrequenciesExtractor(tokenizer)\n",
      "matrix_extractor = bc.SklExtractor(extractor)\n",
      "\n",
      "predictor = pipeline.Pipeline([\n",
      "\t\t('extractor', matrix_extractor),\n",
      "        ('log', Transformer(lambda x: x.tocsr().log1p()) ),\n",
      "\t\t('svd', decomposition.TruncatedSVD(50)),\n",
      "\t\t('svm', svm.SVC(class_weight='auto'))])\n",
      "books, authors = train_collection.as_arrays()\n",
      "scores = cross_validation.cross_val_score(predictor, books, authors,\n",
      "\tscoring='accuracy', cv=cross_validation.StratifiedKFold(authors, n_folds=4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([ 0.11111111,  0.04494382,  0.13483146,  0.04494382])"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}